{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import log, sqrt, exp\n",
    "import scipy.stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the likelihood of data given hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(n1, n2, a, W):\n",
    "    # this function takes a numpy array for n1, n2, and the accuracy (0/1), whether they answerd correctly\n",
    "    # as well as W, the hypothesis\n",
    "    # and returns the *log* likelihood of the responses, log P(acc | n1, n2, W)\n",
    "\n",
    "    assert(len(n1) == len(n2) == len(a))\n",
    "\n",
    "    ll = 0.0\n",
    "    for i in range(len(n1)):\n",
    "        p = 1.0-scipy.stats.norm.cdf(0, loc=abs(n1[i]-n2[i]), \\\n",
    "                                     scale=W*sqrt(n1[i]**2 + n2[i]**2)) # the probability of answering correctly\n",
    "        if a[i] == 1:\n",
    "            ll += log(p) if p > 0.0 else float(\"-inf\")\n",
    "        elif a[i] == 0:\n",
    "            ll += log(1.0-p) if p < 1.0 else float(\"-inf\")\n",
    "        else:\n",
    "            assert(False, \"a[i] must be 0 or 1\")\n",
    "        #print(i,p,ll)\n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Assignment9-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  n1  n2\n",
       "0        1   5   7\n",
       "1        1   4   8\n",
       "2        1   1  13\n",
       "3        1   3   1\n",
       "4        1   1   2\n",
       "5        1   2   1\n",
       "6        1   2   1\n",
       "7        1   1  11\n",
       "8        0   9   5\n",
       "9        1   3   2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3546, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does the data mean?**\n",
    "<br><br>\n",
    "**What is W (Weber's ratio)?**\n",
    "\n",
    "Weber's law states that, as the ratio between the magnitudes of two stimuli increases, the more easily the difference between the two stimuli will be perceived. \n",
    "\n",
    "Models of the ANS utilize Gaussian curves that represent different numerosities, or mental representations of quantity. The spread of these curves is determined by the Weber fraction, hence allowing analysis and comparison of subject performance.\n",
    "The inductive power of understanding the Weber fraction (w) to be an internal scaling factor is also seen when we compare the Weber fractions of different individuals. Individuals differ in the precision of their ANS representations. Some people have more noise and some people have less.\n",
    "\n",
    "Source: http://panamath.org/wiki/index.php?title=What_is_a_Weber_Fraction%3F#The_Weber_Fraction_as_a_Scaling_Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Log Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1801.1498081080333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(data['n1'], data['n2'], data['correct'], 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metroplis (Markov Chain Monte Carlo) Algorithm\n",
    "\n",
    "MCMC is a class of techniques for sampling from a probability distribution and can be used to estimate the distribution of parameters given a set of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Markov Chain? - <br>\n",
    "Markov – future behavior is determined by finite memory of one step back in the past (previous value of W) <br>\n",
    "Chain – We construct a sequence of values by “unfolding” a chain of values in time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Monte Carlo? - <br>\n",
    "Monte Carlo – Our algorithm is stochastic (and actually only gives the right answer if you run it for a “long time”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why log? What happens when you keep multiplying very small numbers? What happens to the multiplication equation if you take a log?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sampler is an algorithm that moves around the set of hypotheses such that the time (number of samples) it spends on H is proportional to P(H|D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(W) :\n",
    "    # Make sure to handle the cases when W<0\n",
    "    return log(exp(-W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20000000000000004"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prior(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(W):\n",
    "    return log_prior(W) + log_likelihood(data['n1'], data['n2'], data['correct'], W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1788.962122891839"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_posterior(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inititate :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis_list = []\n",
    "\n",
    "posterior_score = []\n",
    "\n",
    "\n",
    "hypothesis_list.append(np.random.rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_current = hypothesis_list[-1]\n",
    "\n",
    "w_next = hypothesis_list[-1] + np.random.normal(0, 0.1)\n",
    "\n",
    "rand = np.random.uniform(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10) :\n",
    "    w_current = hypothesis_list[-1]\n",
    "    #print(\"W is : \", w_current)\n",
    "    w_next = hypothesis_list[-1] + np.random.normal(0, 0.1)\n",
    "    #print(\"W' is : \", w_next)\n",
    "    \n",
    "    if ratio of the two probabilities > 1:\n",
    "        hypothesis_list.append(w_next)\n",
    "        posterior_score.append(?)\n",
    "    else :\n",
    "        rand = np.random.uniform(0,1)\n",
    "        ratio = ratio of the two probabilities ## Please pay extra attention here on how to \n",
    "        # calculate the two probabilities, where to take an exponential, \n",
    "        # and how using the log probabilities changes things\n",
    "        # Hint: log(a/b) = log(a) - log(b)\n",
    "        if ratio > rand :\n",
    "            hypothesis_list.append(w_next)\n",
    "            posterior_score.append(?)\n",
    "        else :\n",
    "            hypothesis_list.append(w_current) \n",
    "            posterior_score.append(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "try:\n",
    "    a = np.exp(1000)\n",
    "    print(a)\n",
    "except OverflowError:\n",
    "    print(\"Overflow Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
