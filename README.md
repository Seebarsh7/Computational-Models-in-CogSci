# Computational-Models-in-CogSci
My teaching experiences as a Graduate Student Instructor for Cpmputational Models Cognitive Science. This is a super interesting course that talking about human learning rather than machine learning.   
Probably nobody would see this post but just to remember the sweetest time we had through this semester. **Many thanks to our fantastic staff group**:         
- [Steven Piantadosi](https://vcresearch.berkeley.edu/faculty/steven-piantadosi): One of the best Profs I have ever worked with in my life. Thank you for the buncing ball and thank you for giving me this chance being part of the staff group :))) Anyone pursuing a degree in Cognitive Science at Berkeley who saw this post, please take this class!!! It really touches the soul of human learning and give me a lot of enlightments in my own research in machine learning and transportation! Steve even gave a lecture about how to choose grad schools. He's so nice and willing to help!   
- [Sam Cheyette](http://colala.berkeley.edu/people/SamCheyette/papers.html): Samrt PhD and has deep eyes. Nice to have you to hold OHs on so many Weds :)
- **Aummul Baneen Fidvi**: Graduate Student Instructor from School of IEOR and a super great friend! Wish you all the best in your career (in this nobody-knows post  :p)
- [Shaivya Rastogi](https://www.ischool.berkeley.edu/people/shaivya-rastogi): Organized and always smiling to everyone. Truly happy to meet you!!!    
- [Mugdha Bhusari](https://www.ischool.berkeley.edu/people/mugdha-mangesh-bhusari): Offered me tons of help while I was just start teaching and holding office hours. Good luck for the rest of the degree!!!
- [Michael Levy](https://nature.berkeley.edu/osterlab/people/)       
      
**Clarification: Some of the work in this repo belong to the wisdom of the staff group, not me. Thank you!**
## Assignment 1: Python basics - matplotlib    
topic: Implement the Rescorla-Wagner and plot it!
Nice to know :) 
* Classical conditioning   
  - **Conditioned Stimulus(CS)**: Something not intrinsically rewarding, such as a tone, light, or touch. 
  - **Unconditioned Stimulus(US)** : Something intrinsically rewarding/unpleasant, such as food, warmth, or a shock. 
  - Have CS precede US repeatedly. Result: CS causes response (e.g. salivation, fear) even before presence of US.    
* Rescorla-Wagner     
  - Model of how associative strength changes between CS and US given observations. 
  - How well does the CS predict the US? Learning happens when events violate expectations. 
  - “Prediction error” Greater prediction error ⇒ greater learning.
* Thoughts: does this sound familiar? Dear **Machine Learning**?
  - In machine learning, we all have a goal -> to minimize the loss between machine predictions and ground truth. Algorithms to implement this is the famous 'gradient descent'.   
  - This is the exact process of minimizing prediction error in animials and human beings! 
  - Amazing! Human do the same to learn as algorithms in machine learning process! Or reversely, smart scientists teach machine to learn just in the way of human learning.  
## Assignment 2: Random Walk
